"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[82206],{52551:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>i,default:()=>h,frontMatter:()=>o,metadata:()=>r,toc:()=>c});var s=t(13274),l=t(1780);const o={id:"troubleshooting",title:"Troubleshooting"},i=void 0,r={id:"user_guide/troubleshooting",title:"Troubleshooting",description:"\x3c!--",source:"@site/docs/user_guide/troubleshooting.md",sourceDirName:"user_guide",slug:"/user_guide/troubleshooting",permalink:"/docs/next/user_guide/troubleshooting",draft:!1,unlisted:!1,tags:[],version:"current",frontMatter:{id:"troubleshooting",title:"Troubleshooting"},sidebar:"docs",previous:{title:"Queue",permalink:"/docs/next/metrics/queue"},next:{title:"Dev Environment Setup",permalink:"/docs/next/developer_guide/env_setup"}},a={},c=[{value:"Scheduler logs",id:"scheduler-logs",level:2},{value:"Understanding the linkage between Pod UUID, Task TaskID, AllocationAsk AllocationKey and Allocation AllocationID",id:"understanding-the-linkage-between-pod-uuid-task-taskid-allocationask-allocationkey-and-allocation-allocationid",level:3},{value:"Retrieve scheduler logs",id:"retrieve-scheduler-logs",level:3},{value:"Set Logging Level",id:"set-logging-level",level:3},{value:"Pods are stuck at Pending state",id:"pods-are-stuck-at-pending-state",level:2},{value:"1. Non of the nodes satisfy pod placement requirement",id:"1-non-of-the-nodes-satisfy-pod-placement-requirement",level:3},{value:"2. The queue is running out of capacity",id:"2-the-queue-is-running-out-of-capacity",level:3},{value:"Obtain full state dump",id:"obtain-full-state-dump",level:2},{value:"1. Scheduler URL",id:"1-scheduler-url",level:3},{value:"2. Scheduler REST API",id:"2-scheduler-rest-api",level:3},{value:"Restart the scheduler",id:"restart-the-scheduler",level:2},{value:"Gang Scheduling",id:"gang-scheduling",level:2},{value:"1. No placeholders created, app&#39;s pods are pending",id:"1-no-placeholders-created-apps-pods-are-pending",level:3},{value:"2. Not all placeholders can be allocated",id:"2-not-all-placeholders-can-be-allocated",level:3},{value:"3. Not all placeholders are swapped",id:"3-not-all-placeholders-are-swapped",level:3},{value:"4.Placeholders are not cleaned up when the app terminated",id:"4placeholders-are-not-cleaned-up-when-the-app-terminated",level:3},{value:"Still got questions?",id:"still-got-questions",level:2}];function d(e){const n={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",li:"li",ol:"ol",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.h2,{id:"scheduler-logs",children:"Scheduler logs"}),"\n",(0,s.jsx)(n.h3,{id:"understanding-the-linkage-between-pod-uuid-task-taskid-allocationask-allocationkey-and-allocation-allocationid",children:"Understanding the linkage between Pod UUID, Task TaskID, AllocationAsk AllocationKey and Allocation AllocationID"}),"\n",(0,s.jsxs)(n.p,{children:["Pod is always submitted with ",(0,s.jsx)(n.code,{children:"UID"}),", a unique identifier to differentiate various pods. When a pod is submitted, a ",(0,s.jsx)(n.code,{children:"Task"})," gets created in the Shim. It uses ",(0,s.jsx)(n.code,{children:"UID"})," of the POD as ",(0,s.jsx)(n.code,{children:"TaskID"})," and passed as an ",(0,s.jsx)(n.code,{children:"AllocationAsk"})," request to the core. ",(0,s.jsx)(n.code,{children:"AllocationAsk"})," uses ",(0,s.jsx)(n.code,{children:"Task"}),"'s\n",(0,s.jsx)(n.code,{children:"TaskID"})," as ",(0,s.jsx)(n.code,{children:"AllocationKey"})," and passed onto core for further processing. On receiving the ask request, Core tries to find a suitable\n",(0,s.jsx)(n.code,{children:"Allocation"})," using ",(0,s.jsx)(n.code,{children:"AllocationAsk"}),"'s ",(0,s.jsx)(n.code,{children:"AllocationKey"})," as ",(0,s.jsx)(n.code,{children:"AllocationID"}),". Understanding this flow and its linkage between different objects helps to debug the issues."]}),"\n",(0,s.jsxs)(n.p,{children:["An example has been described below to explain how pod's ",(0,s.jsx)(n.code,{children:"UID"})," is getting translated with different name and passed through different objects."]}),"\n",(0,s.jsx)(n.p,{children:"On task creation,"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",metastring:"script",children:'2023-10-05T10:00:02.224Z  INFO cache/context.go:832 task added  {"appID": "yunikorn-dex-app-mqgh4dw2-autogen", "taskID": "849b762d-68c7-4cce-96e1-5acb545a8620", "taskState": "New"}\n'})}),"\n",(0,s.jsx)(n.p,{children:"On processing allocation,"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",metastring:"script",children:'2023-10-05T10:00:02.523Z  INFO  scheduler/partition.go:890  scheduler allocation processed  {"appID": "yunikorn-dex-app-mqgh4dw2-autogen", "allocationKey": "849b762d-68c7-4cce-96e1-5acb545a8620", "allocationID": "849b762d-68c7-4cce-96e1-5acb545a8620-0", "allocatedResource": "map[memory:343932928 vcore:200]", "placeholder": false, "targetNode": "ip-10-130-86-3.eu-west-1.compute.internal"}\n'})}),"\n",(0,s.jsx)(n.p,{children:"On binding the pod to node,"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",metastring:"script",children:'2023-10-05T10:00:02.523Z  INFO  client/kubeclient.go:112  bind pod to node  {"podName": "dbtdmchicdbdmchicdbstagingdata-1f8b6b53321f4cee9da13a7ac1f2a60c", "podUID": "849b762d-68c7-4cce-96e1-5acb545a8620", "nodeID": "ip-10-130-86-3.eu-west-1.compute.internal"}\n'})}),"\n",(0,s.jsx)(n.h3,{id:"retrieve-scheduler-logs",children:"Retrieve scheduler logs"}),"\n",(0,s.jsxs)(n.p,{children:["Currently, the scheduler writes its logs to stdout/stderr, docker container handles the redirection of these logs to a\nlocal location on the underneath node, you can read more document ",(0,s.jsx)(n.a,{href:"https://docs.docker.com/config/containers/logging/configure/",children:"here"}),".\nThese logs can be retrieved by ",(0,s.jsx)(n.a,{href:"https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#logs",children:"kubectl logs"}),". Such as:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",metastring:"script",children:"// get the scheduler pod\nkubectl get pod -l component=yunikorn-scheduler -n yunikorn\nNAME                                  READY   STATUS    RESTARTS   AGE\nyunikorn-scheduler-766d7d6cdd-44b82   2/2     Running   0          33h\n\n// retrieve logs\nkubectl logs yunikorn-scheduler-766d7d6cdd-44b82 yunikorn-scheduler-k8s -n yunikorn\n"})}),"\n",(0,s.jsxs)(n.p,{children:["In most cases, this command cannot get all logs because the scheduler is rolling logs very fast. To retrieve more logs in\nthe past, you will need to setup the ",(0,s.jsx)(n.a,{href:"https://kubernetes.io/docs/concepts/cluster-administration/logging/#cluster-level-logging-architectures",children:"cluster level logging"}),".\nThe recommended setup is to leverage ",(0,s.jsx)(n.a,{href:"https://www.fluentd.org/",children:"fluentd"})," to collect and persistent logs on an external storage, e.g s3."]}),"\n",(0,s.jsx)(n.h3,{id:"set-logging-level",children:"Set Logging Level"}),"\n",(0,s.jsx)(n.p,{children:"Edit the yunikorn-configs configmap:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",metastring:"script",children:"kubectl edit configmap/yunikorn-configs -n yunikorn\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Add ",(0,s.jsx)(n.code,{children:"log.level"})," to the ",(0,s.jsx)(n.code,{children:"data"})," field of the configmap. For example setting ",(0,s.jsx)(n.code,{children:"log.level"})," to ",(0,s.jsx)(n.code,{children:"DEBUG"})," sets the logging\nlevel to ",(0,s.jsx)(n.code,{children:"DEBUG"}),"."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-yaml",children:"apiVersion: v1\ndata:\n  log.level: DEBUG\n  ...\nkind: ConfigMap\nmetadata:\n   ...\n"})}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"log.level"})," value can be either numeric (-1 through 5) or textual (DEBUG through FATAL)."]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{style:{textAlign:"center"},children:"Value"}),(0,s.jsx)(n.th,{style:{textAlign:"center"},children:"Logging Level"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"-1"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"DEBUG"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"0"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"INFO"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"1"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"WARN"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"2"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"ERROR"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"3"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"DPANIC"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"4"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"PANIC"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"5"}),(0,s.jsx)(n.td,{style:{textAlign:"center"},children:"FATAL"})]})]})]}),"\n",(0,s.jsx)(n.h2,{id:"pods-are-stuck-at-pending-state",children:"Pods are stuck at Pending state"}),"\n",(0,s.jsx)(n.p,{children:"If some pods are stuck at Pending state, that means the scheduler could not find a node to allocate the pod. There are\nseveral possibilities to cause this:"}),"\n",(0,s.jsx)(n.h3,{id:"1-non-of-the-nodes-satisfy-pod-placement-requirement",children:"1. Non of the nodes satisfy pod placement requirement"}),"\n",(0,s.jsxs)(n.p,{children:["A pod can be configured with some placement constraints, such as ",(0,s.jsx)(n.a,{href:"https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector",children:"node-selector"}),",\n",(0,s.jsx)(n.a,{href:"https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity",children:"affinity/anti-affinity"}),",\ndo not have certain toleration for node ",(0,s.jsx)(n.a,{href:"https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/",children:"taints"}),", etc.\nTo debug such issues, you can describe the pod by:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",metastring:"script",children:"kubectl describe pod <pod-name> -n <namespace>\n"})}),"\n",(0,s.jsx)(n.p,{children:"the pod events will contain the predicate failures and that explains why nodes are not qualified for allocation."}),"\n",(0,s.jsx)(n.h3,{id:"2-the-queue-is-running-out-of-capacity",children:"2. The queue is running out of capacity"}),"\n",(0,s.jsx)(n.p,{children:"If the queue is running out of capacity, pods will be pending for available queue resources. To check if a queue is still\nhaving enough capacity for the pending pods, there are several approaches:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsx)(n.li,{children:"check the queue usage from yunikorn UI"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["If you do not know how to access the UI, you can refer the document ",(0,s.jsx)(n.a,{href:"/docs/next/#access-the-web-ui",children:"here"}),". Go\nto the ",(0,s.jsx)(n.code,{children:"Queues"})," page, navigate to the queue where this job is submitted to. You will be able to see the available capacity\nleft for the queue."]}),"\n",(0,s.jsxs)(n.ol,{start:"2",children:["\n",(0,s.jsx)(n.li,{children:"check the pod events"}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Run the ",(0,s.jsx)(n.code,{children:"kubectl describe pod"})," to get the pod events. If you see some event like:\n",(0,s.jsx)(n.code,{children:"Application <appID> does not fit into <queuePath> queue"}),". That means the pod could not get allocated because the queue\nis running out of capacity."]}),"\n",(0,s.jsx)(n.p,{children:"The pod will be allocated if some other pods in this queue is completed or removed. If the pod remains pending even\nthe queue has capacity, that may because it is waiting for the cluster to scale up."}),"\n",(0,s.jsx)(n.h2,{id:"obtain-full-state-dump",children:"Obtain full state dump"}),"\n",(0,s.jsx)(n.p,{children:"A Yunikorn state dump contains the every state object for every process which getting dumped. With endpoint to retrieve we can have many useful information in a single response for troubleshooting for example:  list of partitions, list of applications which includes running, completed also historical application details, number of nodes, utilization of nodes, generic cluster information, cluster utilization details, container history and queues information."}),"\n",(0,s.jsx)(n.p,{children:"The state dump is a valuable resource that Yunikorn offers for use while troubleshooting."}),"\n",(0,s.jsx)(n.p,{children:"There are a few ways to obtain the full state dump."}),"\n",(0,s.jsx)(n.h3,{id:"1-scheduler-url",children:"1. Scheduler URL"}),"\n",(0,s.jsx)(n.p,{children:"STEPS:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Open the Scheduler URL in your browser window/tab and edit the URL as follows:"}),"\n",(0,s.jsxs)(n.li,{children:["Replace ",(0,s.jsx)(n.code,{children:"/#/dashboard"})," with ",(0,s.jsx)(n.code,{children:"/ws/v1/fullstatedump"}),", (For example, ",(0,s.jsx)(n.code,{children:"http://localhost:9889/ws/v1/fullstatedump"}),")"]}),"\n",(0,s.jsx)(n.li,{children:"Press Enter"}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"That displays and provides an easy user experience to view live full state dump."}),"\n",(0,s.jsx)(n.h3,{id:"2-scheduler-rest-api",children:"2. Scheduler REST API"}),"\n",(0,s.jsx)(n.p,{children:"With the below scheduler REST API returns information about full state dump used by the YuniKorn Scheduler."}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.code,{children:"curl -X 'GET' http://localhost:9889/ws/v1/fullstatedump -H 'accept: application/json'"})}),"\n",(0,s.jsxs)(n.p,{children:["For more details around the content of the state dump, please refer to the documentation on ",(0,s.jsx)(n.a,{href:"/docs/next/api/scheduler#retrieve-full-state-dump",children:"retrieve-full-state-dump"})]}),"\n",(0,s.jsx)(n.h2,{id:"restart-the-scheduler",children:"Restart the scheduler"}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsx)(n.p,{children:"In accordance with best practices for troubleshooting, restarting the scheduler should only be done as a last effort to get everything back up and running. It should never be done before gathering all logs and state dumps."})}),"\n",(0,s.jsx)(n.p,{children:"YuniKorn can recover its state upon a restart. YuniKorn scheduler pod is deployed as a deployment, restart the scheduler\ncan be done by scale down and up the replica:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",metastring:"script",children:"kubectl scale deployment yunikorn-scheduler -n yunikorn --replicas=0\nkubectl scale deployment yunikorn-scheduler -n yunikorn --replicas=1\n"})}),"\n",(0,s.jsx)(n.h2,{id:"gang-scheduling",children:"Gang Scheduling"}),"\n",(0,s.jsx)(n.h3,{id:"1-no-placeholders-created-apps-pods-are-pending",children:"1. No placeholders created, app's pods are pending"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"Reason"}),": This is usually because the app is rejected by the scheduler, therefore non of the pods are scheduled.\nThe common reasons caused the rejection are: 1) The taskGroups definition is invalid. The scheduler does the\nsanity check upon app submission, to ensure all the taskGroups are defined correctly, if these info are malformed,\nthe scheduler rejects the app; 2) The total min resources defined in the taskGroups is bigger than the queues' max\ncapacity, scheduler rejects the app because it won't fit into the queue's capacity. Check the pod event for relevant messages,\nand you will also be able to find more detail error messages from the schedulers' log."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"Solution"}),": Correct the taskGroups definition and retry submitting the app."]}),"\n",(0,s.jsx)(n.h3,{id:"2-not-all-placeholders-can-be-allocated",children:"2. Not all placeholders can be allocated"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"Reason"}),": The placeholders also consume resources, if not all of them can be allocated, that usually means either the queue\nor the cluster has no sufficient resources for them. In this case, the placeholders will be cleaned up after a certain\namount of time, defined by the ",(0,s.jsx)(n.code,{children:"placeholderTimeoutInSeconds"})," scheduling policy parameter."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"Solution"}),": Note, if the placeholder timeout reaches, currently the app will transit to failed state and can not be scheduled\nanymore. You can increase the placeholder timeout value if you are willing to wait for a longer time. In the future, a fallback policy\nmight be added to provide some retry other than failing the app."]}),"\n",(0,s.jsx)(n.h3,{id:"3-not-all-placeholders-are-swapped",children:"3. Not all placeholders are swapped"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"Reason"}),": This usually means the actual app's pods are less than the minMembers defined in the taskGroups."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"Solution"}),": Check the ",(0,s.jsx)(n.code,{children:"minMember"})," in the taskGroup field and ensure it is correctly set. The ",(0,s.jsx)(n.code,{children:"minMember"})," can be less than\nthe actual pods, setting it to bigger than the actual number of pods is invalid."]}),"\n",(0,s.jsx)(n.h3,{id:"4placeholders-are-not-cleaned-up-when-the-app-terminated",children:"4.Placeholders are not cleaned up when the app terminated"}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"Reason"}),": All the placeholders are set an ",(0,s.jsx)(n.a,{href:"https://kubernetes.io/docs/concepts/workloads/controllers/garbage-collection/#owners-and-dependents",children:"ownerReference"}),"\nto the first real pod of the app, or the controller reference. If the placeholder could not be cleaned up, that means\nthe garbage collection is not working properly."]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.em,{children:"Solution"}),": check the placeholder ",(0,s.jsx)(n.code,{children:"ownerReference"})," and the garbage collector in Kubernetes."]}),"\n",(0,s.jsx)(n.h2,{id:"still-got-questions",children:"Still got questions?"}),"\n",(0,s.jsx)(n.p,{children:"No problem! The Apache YuniKorn community will be happy to help. You can reach out to the community with the following options:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["Post your questions to ",(0,s.jsx)(n.a,{href:"mailto:dev@yunikorn.apache.org",children:"dev@yunikorn.apache.org"})]}),"\n",(0,s.jsxs)(n.li,{children:["Join the ",(0,s.jsx)(n.a,{href:"https://join.slack.com/t/yunikornworkspace/shared_invite/enQtNzAzMjY0OTI4MjYzLTBmMDdkYTAwNDMwNTE3NWVjZWE1OTczMWE4NDI2Yzg3MmEyZjUyYTZlMDE5M2U4ZjZhNmYyNGFmYjY4ZGYyMGE",children:"YuniKorn slack channel"})," and post your questions to the ",(0,s.jsx)(n.code,{children:"#yunikorn-user"})," channel."]}),"\n",(0,s.jsxs)(n.li,{children:["Join the ",(0,s.jsx)(n.a,{href:"http://yunikorn.apache.org/community/get_involved#community-meetings",children:"community sync up meetings"})," and directly talk to the community members."]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,l.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},1780:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>r});var s=t(79474);const l={},o=s.createContext(l);function i(e){const n=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:i(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);